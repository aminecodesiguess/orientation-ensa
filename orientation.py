import streamlit as st
import os
from langchain_groq import ChatGroq
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from fpdf import FPDF # <-- NOUVEL IMPORT POUR LE PDF

# --- 1. LISTE OFFICIELLE DES FILI√àRES ---
CONSTANTE_FILIERES = """
LISTE OFFICIELLE DES 6 FILI√àRES DE L'ENSA TANGER :
1. G√©nie Syst√®mes et R√©seaux (GSR)
2. G√©nie Informatique (GINF)
3. G√©nie Industriel (GIND)
4. G√©nie des Syst√®mes √âlectroniques et Automatiques (GSEA)
5. G√©nie √ânerg√©tique et Environnement Industriel (G2EI)
6. Cybersecurity and Cyberintelligence (CSI)
"""

# --- 2. CONFIGURATION ---
try:
    GROQ_API_KEY = st.secrets["GROQ_API_KEY"]
except:
    st.error("Erreur : Cl√© API non trouv√©e dans les secrets.")
    st.stop()

st.set_page_config(page_title="Orientation ENSA Tanger", page_icon="üéì", layout="wide")

# --- 3. FONCTION DE G√âN√âRATION PDF (NOUVEAU) ---
def create_pdf(user_profile, ai_response):
    class PDF(FPDF):
        def header(self):
            # Logo
            if os.path.exists("logo.png"):
                self.image("logo.png", 10, 8, 25)
            # Titre
            self.set_font('Arial', 'B', 15)
            self.cell(80) # D√©calage √† droite
            self.cell(30, 10, "Rapport d'Orientation - ENSA Tanger", 0, 0, 'C')
            self.ln(30) # Saut de ligne

        def footer(self):
            self.set_y(-15)
            self.set_font('Arial', 'I', 8)
            self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')

    pdf = PDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    
    # Nettoyage basique des caract√®res non support√©s par FPDF standard (Emojis, etc.)
    def clean_text(text):
        return text.encode('latin-1', 'replace').decode('latin-1')

    # Contenu du Profil
    pdf.set_font("Arial", 'B', 14)
    pdf.cell(0, 10, clean_text("1. Votre Profil √âtudiant"), ln=True)
    pdf.set_font("Arial", size=11)
    pdf.multi_cell(0, 10, clean_text(user_profile))
    pdf.ln(5)

    # Contenu de la Recommandation
    pdf.set_font("Arial", 'B', 14)
    pdf.cell(0, 10, clean_text("2. Recommandation de l'IA"), ln=True)
    pdf.set_font("Arial", size=11)
    pdf.multi_cell(0, 10, clean_text(ai_response))
    
    # Signature
    pdf.ln(10)
    pdf.set_font("Arial", 'I', 10)
    pdf.cell(0, 10, clean_text("Document g√©n√©r√© automatiquement par l'Assistant ENSAT."), ln=True)

    return pdf.output(dest='S').encode('latin-1')

# --- 4. HEADER INTERFACE ---
col1, col2 = st.columns([1, 4])
with col1:
    if os.path.exists("logo.png"):
        st.image("logo.png", width=100)
    else:
        st.markdown("# üè´")
with col2:
    st.title("Assistant Orientation ENSAT")
    st.markdown("**National School of Applied Sciences of Tangier**")

st.divider()

# --- 5. STATE ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "mode" not in st.session_state:
    st.session_state.mode = "chat"
# Variable pour stocker le rapport PDF en m√©moire
if "last_pdf" not in st.session_state:
    st.session_state.last_pdf = None

# --- 6. DATA LOADING ---
@st.cache_resource(show_spinner=False)
def initialize_vectorstore():
    folder_path = "data"
    all_docs = []
    
    if not os.path.exists(folder_path):
        return None, "Dossier 'data' introuvable."
    
    files = [f for f in os.listdir(folder_path) if f.endswith('.pdf') or f.endswith('.txt')]
    if not files:
        return None, "Aucun fichier trouv√©."

    try:
        for filename in files:
            file_path = os.path.join(folder_path, filename)
            if filename.endswith('.pdf'):
                loader = PyPDFLoader(file_path)
            elif filename.endswith('.txt'):
                loader = TextLoader(file_path, encoding='utf-8')
            docs = loader.load()
            all_docs.extend(docs)
            
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
        splits = text_splitter.split_documents(all_docs)
        embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
        vectorstore = FAISS.from_documents(splits, embeddings)
        return vectorstore, None
    except Exception as e:
        return None, str(e)

with st.spinner("Chargement de la base de connaissances..."):
    vectorstore, error_msg = initialize_vectorstore()

if error_msg:
    st.error(error_msg)
    st.stop()

# --- 7. MENU ---
with st.sidebar:
    st.header("üéØ Menu Principal")
    if st.button("üí¨ Chat IA", use_container_width=True): st.session_state.mode = "chat"
    if st.button("üìä Analyseur Notes", use_container_width=True): st.session_state.mode = "grades"
    if st.button("üìù Test Orientation", use_container_width=True): st.session_state.mode = "quiz"
    if st.button("‚öñÔ∏è Comparateur", use_container_width=True): st.session_state.mode = "compare"
    
    st.divider()
    if st.button("üóëÔ∏è Reset"):
        st.session_state.messages = []
        st.session_state.last_pdf = None
        st.rerun()

# --- 8. LOGIQUE PRINCIPALE ---

# MODE QUIZ
if st.session_state.mode == "quiz":
    st.markdown("### üìù Test d'Orientation (15 Questions)")
    with st.form("quiz_15"):
        col_q1, col_q2 = st.columns(2)
        with col_q1:
            st.markdown("**üß† Pr√©f√©rences**")
            q1 = st.radio("1. Passion ?", ["Th√©orie", "Pratique", "Management", "Code"])
            q2 = st.select_slider("2. Maths ?", ["Faible", "Moyen", "Bon", "Excellent"])
            q3 = st.radio("3. Lieu ?", ["Bureau", "Terrain", "Labo", "Usine"])
            q4 = st.radio("4. Social ?", ["Solo", "√âquipe", "Chef"])
            q5 = st.radio("5. Stress ?", ["Non", "Oui", "Moteur"])
            st.markdown("**üíª Tech**")
            q6 = st.radio("6. Code/Prog ?", ["Je d√©teste", "Moyen", "J'adore"]) 
            q7 = st.radio("7. IA ?", ["Non", "Curieux", "Passion"])
            q8 = st.radio("8. T√©l√©coms ?", ["Bof", "Moyen", "Passion"])
        with col_q2:
            st.markdown("**‚öôÔ∏è Indus/Sciences**")
            q9 = st.radio("9. M√©canique ?", ["Ennuyeux", "Utile", "Fascinant"])
            q10 = st.radio("10. √âlec ?", ["Dur", "√áa va", "Top"])
            q11 = st.radio("11. Logistique ?", ["Non", "Moyen", "Top"])
            q12 = st.radio("12. Chimie/Env ?", ["Non", "Moyen", "Oui"])
            st.markdown("**üöÄ Futur**")
            q13 = st.radio("13. BTP ?", ["Non", "Peut-√™tre", "Oui"])
            q14 = st.select_slider("14. Priorit√© ?", ["Passion", "Mix", "Argent"])
            q15 = st.text_input("15. M√©tier r√™ve ?", placeholder="Ex: Data Scientist...")

        if st.form_submit_button("Analyser"):
            with st.spinner("Analyse crois√©e de tes 15 r√©ponses..."):
                # 1. R√©cup√©ration du contexte (Base de donn√©es)
                retriever = vectorstore.as_retriever()
                docs = retriever.invoke("D√©tails modules d√©bouch√©s fili√®res")
                context = "\n".join([d.page_content for d in docs])
                
                # 2. R√©sum√© structur√© des 15 r√©ponses (CRUCIAL pour la pr√©cision)
                summary = f"""
                PROFIL CANDIDAT :
                - Passion dominante : {q1}
                - Niveau Maths : {q2} | Code : {q6} | IA : {q7}
                - Pr√©f√©rences Terrain/Bureau : {q3} | Social : {q4} | Stress : {q5}
                - Int√©r√™ts Tech : T√©l√©coms ({q8})
                - Int√©r√™ts Indus : M√©ca ({q9}), √âlec ({q10}), Logistique ({q11}), Chimie/Env ({q12}), BTP ({q13})
                - Priorit√© vie : {q14}
                - R√™ve : {q15}
                """
                
                # 3. LE PROMPT "EXPERT"
                prompt = f"""
                Tu es un Expert en Orientation Strat√©gique √† l'ENSA Tanger.
                
                TES OUTILS :
                {CONSTANTE_FILIERES}
                
                DONN√âES DU CANDIDAT :
                {summary}
                
                TA MISSION (Analyse Algorithmique) :
                N'invente rien. Base-toi sur la logique suivante pour d√©terminer le TOP 1 et le TOP 2 :
                
                1. LOGIQUE D'√âLIMINATION :
                   - Si "Code" = "Je d√©teste" -> INTERDIRE GINF et CSI.
                   - Si "Maths" = "Faible" -> √âVITER GINF, CSI, GSEA.
                   - Si "Chimie" = "Non" -> √âVITER G2EI.
                
                2. LOGIQUE DE MATCHING (Score Mental) :
                   - GINF : Score √©lev√© si Code="J'adore" + Maths > Moyen.
                   - GIND : Score √©lev√© si Logistique="Top" OU M√©ca="Fascinant" + Gestion.
                   - GSEA : Score √©lev√© si √âlec="Top" + Physique/Auto.
                   - GSR : Score √©lev√© si T√©l√©coms="Passion" + R√©seaux.
                   - G2EI : Score √©lev√© si Chimie/Env="Oui" + √ânergie.
                   - CSI : Score √©lev√© si IA="Passion" + Code="J'adore" + Curiosit√© Cyber.
                
                FORMAT DE R√âPONSE ATTENDU (Markdown) :
                
                ## üèÜ Ta Fili√®re Id√©ale : [Nom de la fili√®re]
                **Pourquoi c'est le match parfait :**
                Explique en 2 phrases en liant ses r√©ponses (ex: "Tu aimes X et Y, or cette fili√®re contient le module Z...").
                
                ## ü•à Alternative Cr√©dible : [Nom de la 2√®me fili√®re]
                Pourquoi celle-ci pourrait aussi te plaire (plan B).
                
                ## ‚ö†Ô∏è Point de Vigilance
                Identifie une faiblesse dans son profil par rapport √† son choix (ex: "Attention, tu dis √™tre faible en Maths, il faudra bosser l'analyse...").
                
                ## üîÆ Projection M√©tier
                Un exemple de m√©tier concret adapt√© √† son r√™ve "{q15}".
                """
                
                # 4. Appel IA avec temp√©rature basse (0.4) pour rester logique mais fluide
                llm = ChatGroq(groq_api_key=GROQ_API_KEY, model_name="llama-3.3-70b-versatile", temperature=0.4)
                resp = llm.invoke(prompt)
                
                # 5. Sauvegarde et PDF
                st.session_state.messages.append({"role": "assistant", "content": f"**R√©sultat de l'Analyse :**\n\n{resp.content}"})
                
                # G√©n√©ration du PDF
                pdf_bytes = create_pdf(f"R√©ponses cl√©s Quiz: {q1}, {q2}, {q6}, {q15}", resp.content)
                st.session_state.last_pdf = pdf_bytes
                st.rerun()

    # Affichage du r√©sultat et du bouton de t√©l√©chargement (hors du formulaire)
    if st.session_state.messages and "R√©sultat Quiz" in st.session_state.messages[-1]["content"]:
        st.success("Analyse termin√©e !")
        st.markdown(st.session_state.messages[-1]["content"])
        
        if st.session_state.last_pdf:
            st.download_button(
                label="üìÑ T√©l√©charger mon Rapport d'Orientation (PDF)",
                data=st.session_state.last_pdf,
                file_name="rapport_orientation_ensa.pdf",
                mime="application/pdf"
            )

# MODE ANALYSEUR NOTES

elif st.session_state.mode == "grades":
    st.markdown("### üìä Analyseur Notes")
    
    # D√©but du formulaire
    with st.form("grades"):
        c1, c2 = st.columns(2)
        with c1:
            m = st.number_input("Maths", 0., 20., 12.)
            p = st.number_input("Physique", 0., 20., 12.)
        with c2:
            i = st.number_input("Info", 0., 20., 12.)
            l = st.number_input("Langues", 0., 20., 12.)
        ch = st.slider("Chimie", 0, 20, 10)
        
        # IMPORTANT : Ce 'if' doit √™tre align√© SOUS les variables m, p, i...
        # Il doit √™tre √† l'int√©rieur du 'with st.form'
        if st.form_submit_button("Calculer"):
            with st.spinner("Analyse approfondie de tes r√©sultats..."):
                # On pr√©pare le contexte
                retriever = vectorstore.as_retriever()
                # Recherche plus cibl√©e
                docs = retriever.invoke("Pr√©requis fili√®res mati√®res") 
                ctx = "\n".join([d.page_content for d in docs])
                
                summary = f"Math√©matiques: {m}/20, Physique: {p}/20, Informatique: {i}/20, Langues: {l}/20, Chimie: {ch}/20"
                
                # --- PROMPT AM√âLIOR√â ---
                prompt = f"""
                Tu es le Directeur P√©dagogique de l'ENSA Tanger. Tu analyses le dossier d'un √©tudiant pour l'orienter.
                
                DONN√âES √âTUDIANT :
                {summary}
                
                CONTEXTE FILI√àRES :
                {CONSTANTE_FILIERES}
                
                TA MISSION :
                1. Calcule un "Score d'Affinit√©" (0-100%) pour chaque fili√®re en suivant cette POND√âRATION LOGIQUE :
                   - GINF & CSI : Coefficient double sur (Maths + Info). Si Info < 12, p√©nalit√© forte.
                   - GSEA & G2EI : Coefficient double sur (Physique + Maths).
                   - GIND : Moyenne √©quilibr√©e, bonus si Maths & Langues sont solides.
                   - GSR : Mix √©quilibr√© Info + R√©seaux (consid√®re Info et Maths).
                
                2. G√©n√®re un tableau Markdown strict avec les colonnes :
                   | Fili√®re | Score % | Verdict | Conseil Rapide |
                
                3. Ajoute une courte analyse textuelle (3 phrases max) sous le tableau pour r√©sumer ses forces et faiblesses.
                
                Sois strict mais encourageant. Si une note est critique (ex: <10), signale-le.
                """
                
                # Appel √† l'IA avec une temp√©rature basse pour √™tre plus "rigoureux"
                llm = ChatGroq(groq_api_key=GROQ_API_KEY, model_name="llama-3.3-70b-versatile", temperature=0.3)
                resp = llm.invoke(prompt)
                
                # Sauvegarde du message
                st.session_state.messages.append({"role": "assistant", "content": resp.content})
                
                # G√©n√©ration PDF
                pdf_bytes = create_pdf(f"Relev√© de notes: {summary}", resp.content)
                st.session_state.last_pdf = pdf_bytes
                st.rerun()

    # --- AFFICHAGE DES R√âSULTATS (HORS DU FORMULAIRE) ---
    # Ici, on reprend l'alignement principal (au niveau du 'with st.form')
    
    # Correction du bug pr√©c√©dent (parenth√®ses ajout√©es)
    if st.session_state.messages and ("Tableau" in str(st.session_state.messages[-1]["content"]) or "Analyse" in str(st.session_state.messages[-1]["content"])):
        st.markdown(st.session_state.messages[-1]["content"])
        
        if st.session_state.last_pdf:
            st.download_button(
                label="üìÑ T√©l√©charger mon Bilan de Notes (PDF)",
                data=st.session_state.last_pdf,
                file_name="bilan_notes_ensa.pdf",
                mime="application/pdf"
            )

# MODE COMPARE
elif st.session_state.mode == "compare":
    st.markdown("### ‚öñÔ∏è Comparateur")
    c1, c2 = st.columns(2)
    f1 = c1.text_input("Fili√®re 1", "GINF")
    f2 = c2.text_input("Fili√®re 2", "GIND")
    if st.button("Comparer"):
        with st.spinner("..."):
            retriever = vectorstore.as_retriever()
            docs = retriever.invoke(f"{f1} {f2}")
            ctx = "\n".join([d.page_content for d in docs])
            prompt = f"Compare {f1} {f2}. Tableau Markdown. Crit√®res: Objectif, Modules, D√©bouch√©s. Contexte: {ctx}"
            llm = ChatGroq(groq_api_key=GROQ_API_KEY, model_name="llama-3.3-70b-versatile")
            resp = llm.invoke(prompt)
            st.markdown(resp.content)
            st.session_state.messages.append({"role": "assistant", "content": resp.content})

# MODE CHAT
elif st.session_state.mode == "chat":
    for m in st.session_state.messages:
        with st.chat_message(m["role"]): st.markdown(m["content"])
    if p := st.chat_input("Question..."):
        with st.chat_message("user"): st.markdown(p)
        st.session_state.messages.append({"role": "user", "content": p})
        with st.chat_message("assistant"):
            retriever = vectorstore.as_retriever()
            docs = retriever.invoke(p)
            ctx = "\n".join([d.page_content for d in docs])
            prompt = f"Expert ENSA. {CONSTANTE_FILIERES}. Contexte: {ctx}. Question: {p}"
            llm = ChatGroq(groq_api_key=GROQ_API_KEY, model_name="llama-3.3-70b-versatile")
            resp = llm.invoke(prompt)
            st.markdown(resp.content)
        st.session_state.messages.append({"role": "assistant", "content": resp.content})




